{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad508ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a965896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingWindows(df, ref_day=1, predict_day=1):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(df.shape[0] - predict_day - ref_day):\n",
    "        X_train.append(np.array(df.iloc[i:i + ref_day]))\n",
    "        Y_train.append(np.array(df.iloc[i + ref_day:i + ref_day + predict_day]['open']))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae4f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelBuilding(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 256, kernel_initializer = 'glorot_normal', return_sequences = True, input_shape = (shape[1], shape[2])))\n",
    "\n",
    "    model.add(LSTM(units = 256, kernel_initializer = 'glorot_normal', return_sequences = True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(5,activation='linear'))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\",metrics=['mean_absolute_error'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b9e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3461350e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186.73</td>\n",
       "      <td>188.71</td>\n",
       "      <td>186.00</td>\n",
       "      <td>186.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185.57</td>\n",
       "      <td>186.33</td>\n",
       "      <td>184.94</td>\n",
       "      <td>185.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184.81</td>\n",
       "      <td>185.03</td>\n",
       "      <td>183.10</td>\n",
       "      <td>184.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184.39</td>\n",
       "      <td>184.48</td>\n",
       "      <td>182.31</td>\n",
       "      <td>182.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182.20</td>\n",
       "      <td>182.27</td>\n",
       "      <td>180.27</td>\n",
       "      <td>181.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>151.95</td>\n",
       "      <td>152.20</td>\n",
       "      <td>151.33</td>\n",
       "      <td>151.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>152.06</td>\n",
       "      <td>152.49</td>\n",
       "      <td>151.62</td>\n",
       "      <td>151.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>152.35</td>\n",
       "      <td>152.93</td>\n",
       "      <td>151.70</td>\n",
       "      <td>152.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>152.81</td>\n",
       "      <td>153.61</td>\n",
       "      <td>152.17</td>\n",
       "      <td>153.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>153.65</td>\n",
       "      <td>154.41</td>\n",
       "      <td>153.08</td>\n",
       "      <td>153.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1488 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open    high     low   close\n",
       "0     186.73  188.71  186.00  186.30\n",
       "1     185.57  186.33  184.94  185.54\n",
       "2     184.81  185.03  183.10  184.66\n",
       "3     184.39  184.48  182.31  182.54\n",
       "4     182.20  182.27  180.27  181.59\n",
       "...      ...     ...     ...     ...\n",
       "1483  151.95  152.20  151.33  151.84\n",
       "1484  152.06  152.49  151.62  151.98\n",
       "1485  152.35  152.93  151.70  152.47\n",
       "1486  152.81  153.61  152.17  153.55\n",
       "1487  153.65  154.41  153.08  153.97\n",
       "\n",
       "[1488 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name = ['open', 'high', 'low', 'close']\n",
    "training = pd.read_csv(\"training_data.csv\", header=None, names=column_name)\n",
    "testing = pd.read_csv(\"testing_data.csv\", header=None, names=column_name)\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa0a8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1481, 6, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = training.copy();\n",
    "trainingData['mid'] = pd.DataFrame((trainingData['high'] + trainingData['low']) / 2)\n",
    "trainingData.dropna()\n",
    "# normailize\n",
    "for col in trainingData.columns:\n",
    "    trainingData[col] = pd.DataFrame(min_max_scaler.fit_transform(pd.DataFrame(trainingData[col])))\n",
    "X_train, Y_train = trainingWindows(trainingData, 6)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06fd2bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 6, 256)            268288    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 6, 256)            525312    \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 6, 1)             257       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 793,898\n",
      "Trainable params: 793,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model building\n",
    "model = modelBuilding(X_train.shape)\n",
    "callback = EarlyStopping(monitor=\"mean_absolute_error\", patience=10, verbose=1, mode=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2787311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "42/42 [==============================] - 4s 18ms/step - loss: 0.0875 - mean_absolute_error: 0.0875 - val_loss: 0.0361 - val_mean_absolute_error: 0.0361\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0292 - mean_absolute_error: 0.0292 - val_loss: 0.0197 - val_mean_absolute_error: 0.0197\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0276 - mean_absolute_error: 0.0276 - val_loss: 0.0180 - val_mean_absolute_error: 0.0180\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0279 - mean_absolute_error: 0.0279 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0293 - mean_absolute_error: 0.0293 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0270 - mean_absolute_error: 0.0270 - val_loss: 0.0179 - val_mean_absolute_error: 0.0179\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0261 - mean_absolute_error: 0.0261 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0277 - mean_absolute_error: 0.0277 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0237 - mean_absolute_error: 0.0237 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0261 - mean_absolute_error: 0.0261 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0269 - mean_absolute_error: 0.0269 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0254 - mean_absolute_error: 0.0254 - val_loss: 0.0175 - val_mean_absolute_error: 0.0175\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0264 - mean_absolute_error: 0.0264 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0243 - mean_absolute_error: 0.0243 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0272 - mean_absolute_error: 0.0272 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0150 - val_mean_absolute_error: 0.0150\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0226 - mean_absolute_error: 0.0226 - val_loss: 0.0140 - val_mean_absolute_error: 0.0140\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0222 - mean_absolute_error: 0.0222 - val_loss: 0.0149 - val_mean_absolute_error: 0.0149\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0242 - mean_absolute_error: 0.0242 - val_loss: 0.0260 - val_mean_absolute_error: 0.0260\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0241 - mean_absolute_error: 0.0241 - val_loss: 0.0227 - val_mean_absolute_error: 0.0227\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0247 - mean_absolute_error: 0.0247 - val_loss: 0.0131 - val_mean_absolute_error: 0.0131\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0234 - mean_absolute_error: 0.0234 - val_loss: 0.0149 - val_mean_absolute_error: 0.0149\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0220 - mean_absolute_error: 0.0220 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0205 - mean_absolute_error: 0.0205 - val_loss: 0.0152 - val_mean_absolute_error: 0.0152\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0207 - mean_absolute_error: 0.0207 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0190 - mean_absolute_error: 0.0190 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0229 - mean_absolute_error: 0.0229 - val_loss: 0.0123 - val_mean_absolute_error: 0.0123\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0205 - mean_absolute_error: 0.0205 - val_loss: 0.0144 - val_mean_absolute_error: 0.0144\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - val_loss: 0.0129 - val_mean_absolute_error: 0.0129\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0212 - mean_absolute_error: 0.0212 - val_loss: 0.0127 - val_mean_absolute_error: 0.0127\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0193 - mean_absolute_error: 0.0193 - val_loss: 0.0122 - val_mean_absolute_error: 0.0122\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - val_loss: 0.0131 - val_mean_absolute_error: 0.0131\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0171 - mean_absolute_error: 0.0171 - val_loss: 0.0125 - val_mean_absolute_error: 0.0125\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0129 - val_mean_absolute_error: 0.0129\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0164 - mean_absolute_error: 0.0164 - val_loss: 0.0137 - val_mean_absolute_error: 0.0137\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0133 - val_mean_absolute_error: 0.0133\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - val_loss: 0.0118 - val_mean_absolute_error: 0.0118\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0166 - mean_absolute_error: 0.0166 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0135 - val_mean_absolute_error: 0.0135\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0178 - mean_absolute_error: 0.0178 - val_loss: 0.0117 - val_mean_absolute_error: 0.0117\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0192 - mean_absolute_error: 0.0192 - val_loss: 0.0122 - val_mean_absolute_error: 0.0122\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0176 - mean_absolute_error: 0.0176 - val_loss: 0.0117 - val_mean_absolute_error: 0.0117\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0162 - mean_absolute_error: 0.0162 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0163 - mean_absolute_error: 0.0163 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0171 - mean_absolute_error: 0.0171 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0156 - mean_absolute_error: 0.0156 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
      "Epoch 51/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0165 - mean_absolute_error: 0.0165 - val_loss: 0.0119 - val_mean_absolute_error: 0.0119\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0163 - mean_absolute_error: 0.0163 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0159 - mean_absolute_error: 0.0159 - val_loss: 0.0106 - val_mean_absolute_error: 0.0106\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0149 - mean_absolute_error: 0.0149 - val_loss: 0.0104 - val_mean_absolute_error: 0.0104\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0156 - mean_absolute_error: 0.0156 - val_loss: 0.0135 - val_mean_absolute_error: 0.0135\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0175 - mean_absolute_error: 0.0175 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0150 - mean_absolute_error: 0.0150 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0163 - mean_absolute_error: 0.0163 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0150 - mean_absolute_error: 0.0150 - val_loss: 0.0099 - val_mean_absolute_error: 0.0099\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0159 - mean_absolute_error: 0.0159 - val_loss: 0.0097 - val_mean_absolute_error: 0.0097\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0152 - mean_absolute_error: 0.0152 - val_loss: 0.0117 - val_mean_absolute_error: 0.0117\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0138 - mean_absolute_error: 0.0138 - val_loss: 0.0096 - val_mean_absolute_error: 0.0096\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0159 - mean_absolute_error: 0.0159 - val_loss: 0.0097 - val_mean_absolute_error: 0.0097\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0148 - mean_absolute_error: 0.0148 - val_loss: 0.0097 - val_mean_absolute_error: 0.0097\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0153 - mean_absolute_error: 0.0153 - val_loss: 0.0105 - val_mean_absolute_error: 0.0105\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0143 - mean_absolute_error: 0.0143 - val_loss: 0.0130 - val_mean_absolute_error: 0.0130\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0150 - mean_absolute_error: 0.0150 - val_loss: 0.0132 - val_mean_absolute_error: 0.0132\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0157 - mean_absolute_error: 0.0157 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0167 - mean_absolute_error: 0.0167 - val_loss: 0.0096 - val_mean_absolute_error: 0.0096\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0144 - mean_absolute_error: 0.0144 - val_loss: 0.0103 - val_mean_absolute_error: 0.0103\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0120 - val_mean_absolute_error: 0.0120\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0102 - val_mean_absolute_error: 0.0102\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0100 - val_mean_absolute_error: 0.0100\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0131 - mean_absolute_error: 0.0131 - val_loss: 0.0084 - val_mean_absolute_error: 0.0084\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0083 - val_mean_absolute_error: 0.0083\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0129 - mean_absolute_error: 0.0129 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0133 - mean_absolute_error: 0.0133 - val_loss: 0.0091 - val_mean_absolute_error: 0.0091\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0125 - mean_absolute_error: 0.0125 - val_loss: 0.0144 - val_mean_absolute_error: 0.0144\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0100 - val_mean_absolute_error: 0.0100\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0129 - val_mean_absolute_error: 0.0129\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0087 - val_mean_absolute_error: 0.0087\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0133 - mean_absolute_error: 0.0133 - val_loss: 0.0099 - val_mean_absolute_error: 0.0099\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0095 - val_mean_absolute_error: 0.0095\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0068 - val_mean_absolute_error: 0.0068\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0069 - val_mean_absolute_error: 0.0069\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0106 - val_mean_absolute_error: 0.0106\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0062 - val_mean_absolute_error: 0.0062\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0062 - val_mean_absolute_error: 0.0062\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0058 - val_mean_absolute_error: 0.0058\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0082 - val_mean_absolute_error: 0.0082\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0060 - val_mean_absolute_error: 0.0060\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0069 - val_mean_absolute_error: 0.0069\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0055 - val_mean_absolute_error: 0.0055\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0083 - val_mean_absolute_error: 0.0083\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0060 - val_mean_absolute_error: 0.0060\n",
      "Epoch 101/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0062 - val_mean_absolute_error: 0.0062\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0060 - val_mean_absolute_error: 0.0060\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0057 - val_mean_absolute_error: 0.0057\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0084 - val_mean_absolute_error: 0.0084\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0086 - val_mean_absolute_error: 0.0086\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0140 - val_mean_absolute_error: 0.0140\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0053 - val_mean_absolute_error: 0.0053\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0056 - val_mean_absolute_error: 0.0056\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0054 - val_mean_absolute_error: 0.0054\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0142 - mean_absolute_error: 0.0142 - val_loss: 0.0084 - val_mean_absolute_error: 0.0084\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0069 - val_mean_absolute_error: 0.0069\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0064 - val_mean_absolute_error: 0.0064\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0057 - val_mean_absolute_error: 0.0057\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0069 - val_mean_absolute_error: 0.0069\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0100 - val_mean_absolute_error: 0.0100\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0057 - val_mean_absolute_error: 0.0057\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0123 - val_mean_absolute_error: 0.0123\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0054 - val_mean_absolute_error: 0.0054\n",
      "Epoch 121/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0056 - val_mean_absolute_error: 0.0056\n",
      "Epoch 122/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0061 - val_mean_absolute_error: 0.0061\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0065 - val_mean_absolute_error: 0.0065\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0068 - val_mean_absolute_error: 0.0068\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0051 - val_mean_absolute_error: 0.0051\n",
      "Epoch 126/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0051 - val_mean_absolute_error: 0.0051\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 128/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0056 - val_mean_absolute_error: 0.0056\n",
      "Epoch 129/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0055 - val_mean_absolute_error: 0.0055\n",
      "Epoch 130/300\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0069 - val_mean_absolute_error: 0.0069\n",
      "Epoch 131/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0063 - val_mean_absolute_error: 0.0063\n",
      "Epoch 00131: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1c74744c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "model.fit(X_train, Y_train, epochs=300, batch_size=32, validation_split=0.1, callbacks=[callback],shuffle=True)\n",
    "# model.fit(X_train, Y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0f9a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makingAction(msg, State):\n",
    "    return {\n",
    "        'BUY': 'HOLD' if State == 1 else 'BUY',\n",
    "        'HOLD': 'HOLD',\n",
    "        'SELL': 'HOLD' if State == -1 else 'SELL',\n",
    "    }[msg]\n",
    "\n",
    "def getAction(action):\n",
    "    return {\n",
    "        'BUY': 1,\n",
    "        'HOLD': 0,\n",
    "        'SELL': -1\n",
    "    }[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2646902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionMaking(Price, State, previousAct, openWindow, D1):\n",
    "    action = 0\n",
    "    \n",
    "    if(previousAct != 0):\n",
    "        Price = (float)(openWindow[-1:])\n",
    "        \n",
    "    monthLine = sum(openWindow)/20\n",
    "    weekLine = sum(openWindow[-6:-1])/5\n",
    "#     print('monthLine:',monthLine,',weekLine:',weekLine)\n",
    "    print((float)(openWindow[-1:]))\n",
    "    y = (float)(openWindow[-2:-1])\n",
    "    t = (float)(openWindow[-1:])\n",
    "    \n",
    "    if(State == 0):\n",
    "        if(D1 > t):\n",
    "            action = getAction(makingAction('BUY', State))\n",
    "        elif(t > D1):\n",
    "            action = getAction(makingAction('SELL', State))\n",
    "    else:\n",
    "        if(State == 1):\n",
    "#             if(Price < D1):\n",
    "#                 action = getAction(makingAction('HOLD', State))\n",
    "#             elif(D1 < Price):\n",
    "#                 action = getAction(makingAction('SELL', State))\n",
    "\n",
    "            if(t < D1):\n",
    "                action = getAction(makingAction('HOLD', State))\n",
    "            elif(D1 < t):\n",
    "                action = getAction(makingAction('SELL', State))\n",
    "        elif(State == -1):\n",
    "            if(t < D1):\n",
    "                action = getAction(makingAction('HOLD', State))\n",
    "            elif(D1 < t):\n",
    "                action = getAction(makingAction('BUY', State)) \n",
    "            \n",
    "    State += action\n",
    "    previousAct = action\n",
    "    return action, Price, State, previousAct, monthLine, weekLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d60b7dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154.40</td>\n",
       "      <td>155.02</td>\n",
       "      <td>152.91</td>\n",
       "      <td>154.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155.96</td>\n",
       "      <td>156.80</td>\n",
       "      <td>155.07</td>\n",
       "      <td>156.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156.45</td>\n",
       "      <td>156.74</td>\n",
       "      <td>154.68</td>\n",
       "      <td>155.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154.10</td>\n",
       "      <td>156.22</td>\n",
       "      <td>154.09</td>\n",
       "      <td>154.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153.59</td>\n",
       "      <td>154.45</td>\n",
       "      <td>153.26</td>\n",
       "      <td>153.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>154.81</td>\n",
       "      <td>155.03</td>\n",
       "      <td>153.55</td>\n",
       "      <td>154.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>155.46</td>\n",
       "      <td>155.89</td>\n",
       "      <td>154.57</td>\n",
       "      <td>155.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156.74</td>\n",
       "      <td>157.85</td>\n",
       "      <td>155.16</td>\n",
       "      <td>156.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156.60</td>\n",
       "      <td>156.73</td>\n",
       "      <td>153.89</td>\n",
       "      <td>153.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>154.60</td>\n",
       "      <td>155.11</td>\n",
       "      <td>153.70</td>\n",
       "      <td>154.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>153.61</td>\n",
       "      <td>153.80</td>\n",
       "      <td>152.03</td>\n",
       "      <td>152.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>153.59</td>\n",
       "      <td>154.18</td>\n",
       "      <td>153.21</td>\n",
       "      <td>153.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>154.05</td>\n",
       "      <td>154.17</td>\n",
       "      <td>153.09</td>\n",
       "      <td>153.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>153.65</td>\n",
       "      <td>153.89</td>\n",
       "      <td>152.78</td>\n",
       "      <td>152.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>153.17</td>\n",
       "      <td>153.46</td>\n",
       "      <td>151.49</td>\n",
       "      <td>151.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>151.82</td>\n",
       "      <td>153.00</td>\n",
       "      <td>151.50</td>\n",
       "      <td>152.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>152.51</td>\n",
       "      <td>153.86</td>\n",
       "      <td>152.50</td>\n",
       "      <td>152.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>152.95</td>\n",
       "      <td>153.18</td>\n",
       "      <td>152.61</td>\n",
       "      <td>153.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>153.20</td>\n",
       "      <td>154.12</td>\n",
       "      <td>153.20</td>\n",
       "      <td>154.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>154.17</td>\n",
       "      <td>154.72</td>\n",
       "      <td>153.42</td>\n",
       "      <td>153.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      open    high     low   close\n",
       "0   154.40  155.02  152.91  154.76\n",
       "1   155.96  156.80  155.07  156.46\n",
       "2   156.45  156.74  154.68  155.35\n",
       "3   154.10  156.22  154.09  154.10\n",
       "4   153.59  154.45  153.26  153.57\n",
       "5   154.81  155.03  153.55  154.81\n",
       "6   155.46  155.89  154.57  155.41\n",
       "7   156.74  157.85  155.16  156.74\n",
       "8   156.60  156.73  153.89  153.91\n",
       "9   154.60  155.11  153.70  154.00\n",
       "10  153.61  153.80  152.03  152.50\n",
       "11  153.59  154.18  153.21  153.33\n",
       "12  154.05  154.17  153.09  153.23\n",
       "13  153.65  153.89  152.78  152.95\n",
       "14  153.17  153.46  151.49  151.50\n",
       "15  151.82  153.00  151.50  152.50\n",
       "16  152.51  153.86  152.50  152.83\n",
       "17  152.95  153.18  152.61  153.13\n",
       "18  153.20  154.12  153.20  154.04\n",
       "19  154.17  154.72  153.42  153.42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = pd.concat((training, testing), axis=0)\n",
    "total['mid'] = pd.DataFrame((total['high'] + total['low']) / 2)\n",
    "total.reset_index(inplace=True, drop=True)\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2008b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.65\n",
      "154.4\n",
      "155.96\n",
      "156.45\n",
      "154.1\n",
      "153.59\n",
      "154.81\n",
      "155.46\n",
      "156.74\n",
      "156.6\n",
      "154.6\n",
      "153.61\n",
      "153.59\n",
      "154.05\n",
      "153.65\n",
      "153.17\n",
      "151.82\n",
      "152.51\n",
      "152.95\n",
      "[1, 0, 0, -1, 1, 0, 0, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "locat = len(training)\n",
    "result = []\n",
    "MLs = []\n",
    "WLs = []\n",
    "actions = []\n",
    "Price = 0.0\n",
    "State = 0\n",
    "previousAct = 0\n",
    "for i in range(locat, locat + len(testing) -1):\n",
    "    data = total[0:i].copy()\n",
    "    openWindow = data['open'][-20:].copy()\n",
    "    for col in data.columns:\n",
    "        data[col] = pd.DataFrame(min_max_scaler.fit_transform(pd.DataFrame(data[col])))\n",
    "    predictData = [data[i-6:i]]\n",
    "    prediction = min_max_scaler.inverse_transform(model.predict(np.array(predictData)))\n",
    "    D1 = prediction[0][0]\n",
    "    result.append(D1)\n",
    "    action, p, s, pa, ML, WL = decisionMaking(Price, State, previousAct, openWindow, D1)\n",
    "    actions.append(action)\n",
    "    MLs.append(ML)\n",
    "    WLs.append(WL)\n",
    "    Price = p\n",
    "    State = s\n",
    "    previousAct = pa \n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a0c31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938335338787245"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "mean_squared_error(testing['open'][:-1], result, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d047f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw\n",
    "index = np.array([i for i in range(len(result))])\n",
    "plt.plot(index, np.array(testing['open'][:-1]), color='red', label='real_value')\n",
    "plt.plot(index, np.array(result), color='blue', label='predicted_value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
