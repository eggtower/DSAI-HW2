{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad508ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a965896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingWindows(df, ref_day=1, predict_day=1):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(df.shape[0] - predict_day - ref_day):\n",
    "        X_train.append(np.array(df.iloc[i:i + ref_day]))\n",
    "        Y_train.append(np.array(df.iloc[i + ref_day:i + ref_day + predict_day]['open']))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae4f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelBuilding(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 256, kernel_initializer = 'glorot_normal', return_sequences = True, input_shape = (shape[1], shape[2])))\n",
    "\n",
    "    model.add(LSTM(units = 256, kernel_initializer = 'glorot_normal', return_sequences = True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(5,activation='linear'))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\",metrics=['mean_absolute_error'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b9e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3461350e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186.73</td>\n",
       "      <td>188.71</td>\n",
       "      <td>186.00</td>\n",
       "      <td>186.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185.57</td>\n",
       "      <td>186.33</td>\n",
       "      <td>184.94</td>\n",
       "      <td>185.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184.81</td>\n",
       "      <td>185.03</td>\n",
       "      <td>183.10</td>\n",
       "      <td>184.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184.39</td>\n",
       "      <td>184.48</td>\n",
       "      <td>182.31</td>\n",
       "      <td>182.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182.20</td>\n",
       "      <td>182.27</td>\n",
       "      <td>180.27</td>\n",
       "      <td>181.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>151.95</td>\n",
       "      <td>152.20</td>\n",
       "      <td>151.33</td>\n",
       "      <td>151.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>152.06</td>\n",
       "      <td>152.49</td>\n",
       "      <td>151.62</td>\n",
       "      <td>151.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>152.35</td>\n",
       "      <td>152.93</td>\n",
       "      <td>151.70</td>\n",
       "      <td>152.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>152.81</td>\n",
       "      <td>153.61</td>\n",
       "      <td>152.17</td>\n",
       "      <td>153.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>153.65</td>\n",
       "      <td>154.41</td>\n",
       "      <td>153.08</td>\n",
       "      <td>153.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1488 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open    high     low   close\n",
       "0     186.73  188.71  186.00  186.30\n",
       "1     185.57  186.33  184.94  185.54\n",
       "2     184.81  185.03  183.10  184.66\n",
       "3     184.39  184.48  182.31  182.54\n",
       "4     182.20  182.27  180.27  181.59\n",
       "...      ...     ...     ...     ...\n",
       "1483  151.95  152.20  151.33  151.84\n",
       "1484  152.06  152.49  151.62  151.98\n",
       "1485  152.35  152.93  151.70  152.47\n",
       "1486  152.81  153.61  152.17  153.55\n",
       "1487  153.65  154.41  153.08  153.97\n",
       "\n",
       "[1488 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name = ['open', 'high', 'low', 'close']\n",
    "training = pd.read_csv(\"training_data.csv\", header=None, names=column_name)\n",
    "testing = pd.read_csv(\"testing_data.csv\", header=None, names=column_name)\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa0a8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1481, 6, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = training.copy();\n",
    "trainingData['mid'] = pd.DataFrame((trainingData['high'] + trainingData['low']) / 2)\n",
    "trainingData.dropna()\n",
    "# normailize\n",
    "for col in trainingData.columns:\n",
    "    trainingData[col] = pd.DataFrame(min_max_scaler.fit_transform(pd.DataFrame(trainingData[col])))\n",
    "X_train, Y_train = trainingWindows(trainingData, 6)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06fd2bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 6, 256)            268288    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 6, 256)            525312    \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 6, 1)             257       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 793,898\n",
      "Trainable params: 793,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model building\n",
    "model = modelBuilding(X_train.shape)\n",
    "callback = EarlyStopping(monitor=\"mean_absolute_error\", patience=10, verbose=1, mode=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2787311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "42/42 [==============================] - 4s 17ms/step - loss: 0.1129 - mean_absolute_error: 0.1129 - val_loss: 0.0303 - val_mean_absolute_error: 0.0303\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0263 - mean_absolute_error: 0.0263 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0249 - mean_absolute_error: 0.0249 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0261 - mean_absolute_error: 0.0261 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0244 - mean_absolute_error: 0.0244 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0216 - mean_absolute_error: 0.0216 - val_loss: 0.0136 - val_mean_absolute_error: 0.0136\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0313 - mean_absolute_error: 0.0313 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0228 - mean_absolute_error: 0.0228 - val_loss: 0.0140 - val_mean_absolute_error: 0.0140\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0226 - mean_absolute_error: 0.0226 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0211 - mean_absolute_error: 0.0211 - val_loss: 0.0123 - val_mean_absolute_error: 0.0123\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0233 - mean_absolute_error: 0.0233 - val_loss: 0.0121 - val_mean_absolute_error: 0.0121\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0229 - mean_absolute_error: 0.0229 - val_loss: 0.0182 - val_mean_absolute_error: 0.0182\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0204 - mean_absolute_error: 0.0204 - val_loss: 0.0114 - val_mean_absolute_error: 0.0114\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0177 - mean_absolute_error: 0.0177 - val_loss: 0.0119 - val_mean_absolute_error: 0.0119\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0178 - mean_absolute_error: 0.0178 - val_loss: 0.0113 - val_mean_absolute_error: 0.0113\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0167 - mean_absolute_error: 0.0167 - val_loss: 0.0127 - val_mean_absolute_error: 0.0127\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0177 - mean_absolute_error: 0.0177 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0151 - mean_absolute_error: 0.0151 - val_loss: 0.0090 - val_mean_absolute_error: 0.0090\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0090 - val_mean_absolute_error: 0.0090\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0156 - mean_absolute_error: 0.0156 - val_loss: 0.0101 - val_mean_absolute_error: 0.0101\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0164 - mean_absolute_error: 0.0164 - val_loss: 0.0102 - val_mean_absolute_error: 0.0102\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0102 - val_mean_absolute_error: 0.0102\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0161 - mean_absolute_error: 0.0161 - val_loss: 0.0093 - val_mean_absolute_error: 0.0093\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0129 - mean_absolute_error: 0.0129 - val_loss: 0.0102 - val_mean_absolute_error: 0.0102\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0144 - mean_absolute_error: 0.0144 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0112 - val_mean_absolute_error: 0.0112\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.0088 - val_mean_absolute_error: 0.0088\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0139 - mean_absolute_error: 0.0139 - val_loss: 0.0096 - val_mean_absolute_error: 0.0096\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0138 - mean_absolute_error: 0.0138 - val_loss: 0.0126 - val_mean_absolute_error: 0.0126\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0154 - mean_absolute_error: 0.0154 - val_loss: 0.0081 - val_mean_absolute_error: 0.0081\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0126 - mean_absolute_error: 0.0126 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0157 - mean_absolute_error: 0.0157 - val_loss: 0.0094 - val_mean_absolute_error: 0.0094\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0129 - mean_absolute_error: 0.0129 - val_loss: 0.0098 - val_mean_absolute_error: 0.0098\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0096 - val_mean_absolute_error: 0.0096\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0133 - mean_absolute_error: 0.0133 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0091 - val_mean_absolute_error: 0.0091\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0137 - mean_absolute_error: 0.0137 - val_loss: 0.0088 - val_mean_absolute_error: 0.0088\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0119 - mean_absolute_error: 0.0119 - val_loss: 0.0125 - val_mean_absolute_error: 0.0125\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0156 - mean_absolute_error: 0.0156 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0139 - mean_absolute_error: 0.0139 - val_loss: 0.0084 - val_mean_absolute_error: 0.0084\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0084 - val_mean_absolute_error: 0.0084\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0134 - val_mean_absolute_error: 0.0134\n",
      "Epoch 51/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0187 - val_mean_absolute_error: 0.0187\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0139 - mean_absolute_error: 0.0139 - val_loss: 0.0071 - val_mean_absolute_error: 0.0071\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0096 - val_mean_absolute_error: 0.0096\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0138 - mean_absolute_error: 0.0138 - val_loss: 0.0097 - val_mean_absolute_error: 0.0097\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0071 - val_mean_absolute_error: 0.0071\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0068 - val_mean_absolute_error: 0.0068\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0140 - mean_absolute_error: 0.0140 - val_loss: 0.0096 - val_mean_absolute_error: 0.0096\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0089 - val_mean_absolute_error: 0.0089\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0144 - mean_absolute_error: 0.0144 - val_loss: 0.0091 - val_mean_absolute_error: 0.0091\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0068 - val_mean_absolute_error: 0.0068\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0069 - val_mean_absolute_error: 0.0069\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0070 - val_mean_absolute_error: 0.0070\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0147 - mean_absolute_error: 0.0147 - val_loss: 0.0122 - val_mean_absolute_error: 0.0122\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0132 - mean_absolute_error: 0.0132 - val_loss: 0.0067 - val_mean_absolute_error: 0.0067\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0067 - val_mean_absolute_error: 0.0067\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0126 - mean_absolute_error: 0.0126 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0129 - mean_absolute_error: 0.0129 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0065 - val_mean_absolute_error: 0.0065\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0126 - mean_absolute_error: 0.0126 - val_loss: 0.0070 - val_mean_absolute_error: 0.0070\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0082 - val_mean_absolute_error: 0.0082\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0066 - val_mean_absolute_error: 0.0066\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0064 - val_mean_absolute_error: 0.0064\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0088 - val_mean_absolute_error: 0.0088\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0089 - val_mean_absolute_error: 0.0089\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0067 - val_mean_absolute_error: 0.0067\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0110 - val_mean_absolute_error: 0.0110\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0070 - val_mean_absolute_error: 0.0070\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0095 - val_mean_absolute_error: 0.0095\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0073 - val_mean_absolute_error: 0.0073\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0061 - val_mean_absolute_error: 0.0061\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0060 - val_mean_absolute_error: 0.0060\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0072 - val_mean_absolute_error: 0.0072\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0114 - mean_absolute_error: 0.0114 - val_loss: 0.0069 - val_mean_absolute_error: 0.0069\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0063 - val_mean_absolute_error: 0.0063\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0059 - val_mean_absolute_error: 0.0059\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0069 - val_mean_absolute_error: 0.0069\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0063 - val_mean_absolute_error: 0.0063\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0061 - val_mean_absolute_error: 0.0061\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0143 - mean_absolute_error: 0.0143 - val_loss: 0.0061 - val_mean_absolute_error: 0.0061\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0067 - val_mean_absolute_error: 0.0067\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0057 - val_mean_absolute_error: 0.0057\n",
      "Epoch 101/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0096 - val_mean_absolute_error: 0.0096\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0068 - val_mean_absolute_error: 0.0068\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0090 - val_mean_absolute_error: 0.0090\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0065 - val_mean_absolute_error: 0.0065\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0149 - val_mean_absolute_error: 0.0149\n",
      "Epoch 00106: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x251815d6508>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "model.fit(X_train, Y_train, epochs=300, batch_size=32, validation_split=0.1, callbacks=[callback],shuffle=True)\n",
    "# model.fit(X_train, Y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0f9a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makingAction(msg, State):\n",
    "    return {\n",
    "        'BUY': 'HOLD' if State == 1 else 'BUY',\n",
    "        'HOLD': 'HOLD',\n",
    "        'SELL': 'HOLD' if State == -1 else 'SELL',\n",
    "    }[msg]\n",
    "\n",
    "def getAction(action):\n",
    "    return {\n",
    "        'BUY': 1,\n",
    "        'HOLD': 0,\n",
    "        'SELL': -1\n",
    "    }[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2646902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionMaking(Price, State, previousAct, openWindow, D1):\n",
    "    action = 0\n",
    "    \n",
    "    if(previousAct != 0):\n",
    "        Price = (float)(openWindow[-1:])\n",
    "        \n",
    "    monthLine = sum(openWindow)/20\n",
    "    weekLine = sum(openWindow[-6:-1])/5\n",
    "#     print('monthLine:',monthLine,',weekLine:',weekLine)\n",
    "    print((float)(openWindow[-1:]))\n",
    "    y = (float)(openWindow[-2:-1])\n",
    "    t = (float)(openWindow[-1:])\n",
    "    \n",
    "    if(State == 0):\n",
    "        if(D1 > t):\n",
    "            action = getAction(makingAction('BUY', State))\n",
    "        elif(t > D1):\n",
    "            action = getAction(makingAction('SELL', State))\n",
    "    else:\n",
    "        if(State == 1):\n",
    "#             if(Price < D1):\n",
    "#                 action = getAction(makingAction('HOLD', State))\n",
    "#             elif(D1 < Price):\n",
    "#                 action = getAction(makingAction('SELL', State))\n",
    "\n",
    "            if(t < D1):\n",
    "                action = getAction(makingAction('HOLD', State))\n",
    "            elif(D1 < t):\n",
    "                action = getAction(makingAction('SELL', State))\n",
    "        elif(State == -1):\n",
    "            if(t < D1):\n",
    "                action = getAction(makingAction('HOLD', State))\n",
    "            elif(D1 < t):\n",
    "                action = getAction(makingAction('BUY', State)) \n",
    "            \n",
    "    State += action\n",
    "    previousAct = action\n",
    "    return action, Price, State, previousAct, monthLine, weekLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d60b7dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154.40</td>\n",
       "      <td>155.02</td>\n",
       "      <td>152.91</td>\n",
       "      <td>154.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155.96</td>\n",
       "      <td>156.80</td>\n",
       "      <td>155.07</td>\n",
       "      <td>156.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156.45</td>\n",
       "      <td>156.74</td>\n",
       "      <td>154.68</td>\n",
       "      <td>155.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154.10</td>\n",
       "      <td>156.22</td>\n",
       "      <td>154.09</td>\n",
       "      <td>154.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153.59</td>\n",
       "      <td>154.45</td>\n",
       "      <td>153.26</td>\n",
       "      <td>153.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>154.81</td>\n",
       "      <td>155.03</td>\n",
       "      <td>153.55</td>\n",
       "      <td>154.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>155.46</td>\n",
       "      <td>155.89</td>\n",
       "      <td>154.57</td>\n",
       "      <td>155.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156.74</td>\n",
       "      <td>157.85</td>\n",
       "      <td>155.16</td>\n",
       "      <td>156.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156.60</td>\n",
       "      <td>156.73</td>\n",
       "      <td>153.89</td>\n",
       "      <td>153.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>154.60</td>\n",
       "      <td>155.11</td>\n",
       "      <td>153.70</td>\n",
       "      <td>154.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>153.61</td>\n",
       "      <td>153.80</td>\n",
       "      <td>152.03</td>\n",
       "      <td>152.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>153.59</td>\n",
       "      <td>154.18</td>\n",
       "      <td>153.21</td>\n",
       "      <td>153.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>154.05</td>\n",
       "      <td>154.17</td>\n",
       "      <td>153.09</td>\n",
       "      <td>153.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>153.65</td>\n",
       "      <td>153.89</td>\n",
       "      <td>152.78</td>\n",
       "      <td>152.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>153.17</td>\n",
       "      <td>153.46</td>\n",
       "      <td>151.49</td>\n",
       "      <td>151.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>151.82</td>\n",
       "      <td>153.00</td>\n",
       "      <td>151.50</td>\n",
       "      <td>152.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>152.51</td>\n",
       "      <td>153.86</td>\n",
       "      <td>152.50</td>\n",
       "      <td>152.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>152.95</td>\n",
       "      <td>153.18</td>\n",
       "      <td>152.61</td>\n",
       "      <td>153.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>153.20</td>\n",
       "      <td>154.12</td>\n",
       "      <td>153.20</td>\n",
       "      <td>154.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>154.17</td>\n",
       "      <td>154.72</td>\n",
       "      <td>153.42</td>\n",
       "      <td>153.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      open    high     low   close\n",
       "0   154.40  155.02  152.91  154.76\n",
       "1   155.96  156.80  155.07  156.46\n",
       "2   156.45  156.74  154.68  155.35\n",
       "3   154.10  156.22  154.09  154.10\n",
       "4   153.59  154.45  153.26  153.57\n",
       "5   154.81  155.03  153.55  154.81\n",
       "6   155.46  155.89  154.57  155.41\n",
       "7   156.74  157.85  155.16  156.74\n",
       "8   156.60  156.73  153.89  153.91\n",
       "9   154.60  155.11  153.70  154.00\n",
       "10  153.61  153.80  152.03  152.50\n",
       "11  153.59  154.18  153.21  153.33\n",
       "12  154.05  154.17  153.09  153.23\n",
       "13  153.65  153.89  152.78  152.95\n",
       "14  153.17  153.46  151.49  151.50\n",
       "15  151.82  153.00  151.50  152.50\n",
       "16  152.51  153.86  152.50  152.83\n",
       "17  152.95  153.18  152.61  153.13\n",
       "18  153.20  154.12  153.20  154.04\n",
       "19  154.17  154.72  153.42  153.42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = pd.concat((training, testing), axis=0)\n",
    "total['mid'] = pd.DataFrame((total['high'] + total['low']) / 2)\n",
    "total.reset_index(inplace=True, drop=True)\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2008b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.65\n",
      "154.4\n",
      "155.96\n",
      "156.45\n",
      "154.1\n",
      "153.59\n",
      "154.81\n",
      "155.46\n",
      "156.74\n",
      "156.6\n",
      "154.6\n",
      "153.61\n",
      "153.59\n",
      "154.05\n",
      "153.65\n",
      "153.17\n",
      "151.82\n",
      "152.51\n",
      "152.95\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "locat = len(training)\n",
    "result = []\n",
    "MLs = []\n",
    "WLs = []\n",
    "actions = []\n",
    "Price = 0.0\n",
    "State = 0\n",
    "previousAct = 0\n",
    "for i in range(locat, locat + len(testing) -1):\n",
    "    data = total[0:i].copy()\n",
    "    openWindow = data['open'][-20:].copy()\n",
    "    for col in data.columns:\n",
    "        data[col] = pd.DataFrame(min_max_scaler.fit_transform(pd.DataFrame(data[col])))\n",
    "    predictData = [data[i-6:i]]\n",
    "    prediction = min_max_scaler.inverse_transform(model.predict(np.array(predictData)))\n",
    "    D1 = prediction[0][0]\n",
    "    result.append(D1)\n",
    "    action, p, s, pa, ML, WL = decisionMaking(Price, State, previousAct, openWindow, D1)\n",
    "    actions.append(action)\n",
    "    MLs.append(ML)\n",
    "    WLs.append(WL)\n",
    "    Price = p\n",
    "    State = s\n",
    "    previousAct = pa \n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a0c31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2231127447409342"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "mean_squared_error(testing['open'][:-1], result, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d047f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw\n",
    "index = np.array([i for i in range(len(result))])\n",
    "plt.plot(index, np.array(testing['open'][:-1]), color='red', label='real_value')\n",
    "plt.plot(index, np.array(result), color='blue', label='predicted_value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
